{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "demoApplyToVideo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0raDBAcukRE",
        "outputId": "7f9ae013-50cf-4e6f-88b3-bc79f48036b7"
      },
      "source": [
        "# just in case\n",
        "!pip install tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj0aI2iv_BLw",
        "outputId": "1b8e7c50-6ebc-4c0f-9d73-8d18642aed6e"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# drive.flush_and_unmount()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD4i9x70-fCx"
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO0loo7S-fCx"
      },
      "source": [
        "def ExtractFrames(file_path, pos=[0,0.05,0.1,0.15,.02,.25,.30,.35,.40,.45,.50,.55,.60,.65,.70,.75,.80,.85,.9,.95]):\n",
        "    # Extracts frames from file_path at the positions (relative between 0 and 1) in pos\n",
        "    \n",
        "    import os\n",
        "    \n",
        "    if not len(pos):\n",
        "        print(\"[ExtractFrames]: Invalid positions\")\n",
        "        return None\n",
        "    \n",
        "    if not os.path.isfile(file_path) :\n",
        "        print(\"[ExtractFrames]: Invalid file path\")\n",
        "        return None\n",
        "    \n",
        "    import cv2\n",
        "    \n",
        "    # container for frames\n",
        "    arr = np.empty((len(pos),224,224,3))\n",
        "    \n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    \n",
        "    for k,i in enumerate(pos):\n",
        "        # get frame number\n",
        "        position = int(i * total_frames)\n",
        "        \n",
        "        # set frame pointer at i and extract frame\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        # preprocessing\n",
        "        frame = cv2.resize(frame, (224,224))\n",
        "        frame = frame * 1/255.\n",
        "        frame = np.float32(frame)\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # insert in container\n",
        "        arr[k] = frame\n",
        "        \n",
        "    # cleanup\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    cap.release()\n",
        "    \n",
        "    return arr"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozn0bg7-fCy"
      },
      "source": [
        "# Load our already trained model\n",
        "model = load_model(r\"/content/drive/MyDrive/CSCE636/v6/new_model_V6_lr_0.0005.h5\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4cBHp0Ru2y-"
      },
      "source": [
        "# Get frames from our desired test video\n",
        "TestVideo = ExtractFrames(r\"/content/drive/MyDrive/CSCE636/v6/ApplyVideo.mp4\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhoJdhjru4ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098afd0a-bfef-418a-9a16-fa0ca041a9f2"
      },
      "source": [
        "# need to reshape input to include sample size.\n",
        "# in this case sample size is 1\n",
        "TestVideo = np.expand_dims(TestVideo, axis=0)\n",
        "TestVideo.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 20, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtZYYAypBDAJ"
      },
      "source": [
        "# perform prediction. Note this command works for only a single video\n",
        "pred = model(TestVideo)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU1_kwZGPTC_"
      },
      "source": [
        "# convert tensor to array\n",
        "pred = pred.numpy()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MC3C9_5QItM",
        "outputId": "2baf85a5-b5a8-4f2a-aaa8-9ad592a2d5f5"
      },
      "source": [
        "# The first index represents reading, the second is not reading\n",
        "pred"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9943739e-01, 5.6255545e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5x1VzGMBUvN"
      },
      "source": [
        "index_max = np.argmax(pred, axis=1)\n",
        "# \"Reading\" - 1, \"not Reading\" - 0\n",
        "# if argmax is index 0, then it predicted reading, hence\n",
        "# assign a 1 or else assign a 0\n",
        "lookup = {1:0, 0:1}\n",
        "predicted_labels = np.array([lookup[i] for i in index_max])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-S8DmJQaxS",
        "outputId": "bd218296-6121-40c6-dd9a-d09921b05c9a"
      },
      "source": [
        "# a value of one means we detected the action!\n",
        "predicted_labels[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pwGNHsLCbpP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlN-7v0fCb_D"
      },
      "source": [
        "# DO NOT RUN\n",
        "\n",
        "# import os\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# counter = 0\n",
        "# suc_vids = []\n",
        "# path=r'/content/drive/MyDrive/CSCE636/v6'\n",
        "# for vid in tqdm(os.listdir(path)):\n",
        "#   vid = os.path.join(path, vid)\n",
        "#   TestVideo = ExtractFrames(vid)\n",
        "#   TestVideo = np.expand_dims(TestVideo, axis=0)\n",
        "\n",
        "#   flag = 1 - np.argmax(model(TestVideo).numpy(), axis=1)\n",
        "#   if flag:\n",
        "#     counter += 1\n",
        "#     suc_vids.append(vid)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWxDqMV2FYww"
      },
      "source": [
        "# print(len(os.listdir(path)))\n",
        "# for vid in os.listdir(path):\n",
        "#   if os.path.join(path, vid) not in suc_vids:\n",
        "#     print(vid)"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}