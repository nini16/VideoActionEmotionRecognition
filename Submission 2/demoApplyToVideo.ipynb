{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "demoApplyToVideo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0raDBAcukRE",
        "outputId": "9d3e2075-d6b0-4e0a-d746-5caaa0803dea"
      },
      "source": [
        "# just in case\r\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj0aI2iv_BLw",
        "outputId": "d96d1e39-4e27-46bf-cf55-96825ba1c0aa"
      },
      "source": [
        "# mount google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')\r\n",
        "# drive.flush_and_unmount()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD4i9x70-fCx"
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO0loo7S-fCx"
      },
      "source": [
        "def ExtractFrames(file_path, pos=[0.1,0.3,0.5,0.7,0.9]):\r\n",
        "    # Extracts frames from file_path at the positions (relative between 0 and 1) in pos\r\n",
        "    \r\n",
        "    import os\r\n",
        "    \r\n",
        "    if not len(pos):\r\n",
        "        print(\"[ExtractFrames]: Invalid positions\")\r\n",
        "        return None\r\n",
        "    \r\n",
        "    if not os.path.isfile(file_path) :\r\n",
        "        print(\"[ExtractFrames]: Invalid file path\")\r\n",
        "        return None\r\n",
        "    \r\n",
        "    import cv2\r\n",
        "    \r\n",
        "    # container for frames\r\n",
        "    arr = np.empty((len(pos),224,224,3))\r\n",
        "    \r\n",
        "    cap = cv2.VideoCapture(file_path)\r\n",
        "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\r\n",
        "    \r\n",
        "    for k,i in enumerate(pos):\r\n",
        "        # get frame number\r\n",
        "        position = int(i * total_frames)\r\n",
        "        \r\n",
        "        # set frame pointer at i and extract frame\r\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\r\n",
        "        ret, frame = cap.read()\r\n",
        "        \r\n",
        "        # preprocessing\r\n",
        "        frame = cv2.resize(frame, (224,224))\r\n",
        "        frame = frame * 1/255.\r\n",
        "        frame = np.float32(frame)\r\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
        "        \r\n",
        "        # insert in container\r\n",
        "        arr[k] = frame\r\n",
        "        \r\n",
        "    # cleanup\r\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\r\n",
        "    cap.release()\r\n",
        "    \r\n",
        "    return arr"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozn0bg7-fCy"
      },
      "source": [
        "# Load our already trained model\r\n",
        "model = load_model(\"/content/drive/MyDrive/CSCE636/main_model.h5\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4cBHp0Ru2y-"
      },
      "source": [
        "# Get frames from our desired test video\r\n",
        "TestVideo = ExtractFrames(r\"/content/drive/MyDrive/CSCE636/DemoApplyTestVideo.mp4\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhoJdhjru4ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9adb3b-e4b9-4b4d-d626-0df75c252d41"
      },
      "source": [
        "# need to reshape input to include sample size.\r\n",
        "# in this case sample size is 1\r\n",
        "TestVideo = np.expand_dims(TestVideo, axis=0)\r\n",
        "TestVideo.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtZYYAypBDAJ"
      },
      "source": [
        "# perform prediction. Note this command works for only a single video\r\n",
        "pred = model(TestVideo)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU1_kwZGPTC_"
      },
      "source": [
        "# convert tensor to array\r\n",
        "pred = pred.numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MC3C9_5QItM",
        "outputId": "7b11e083-098b-47fd-9a88-e92cc908b114"
      },
      "source": [
        "# The first index represents brusing teeth, the second is not brushing teeth\r\n",
        "pred"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.93660915, 0.06339087]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5x1VzGMBUvN"
      },
      "source": [
        "index_max = np.argmax(pred, axis=1)\r\n",
        "# \"brushing_teeth\" - 1, \"not brushing_teeth\" - 0\r\n",
        "# if argmax is index 0, then it predicted brushing teeth, hence\r\n",
        "# assign a 1 or else assign a 0\r\n",
        "lookup = {1:0, 0:1}\r\n",
        "predicted_labels = np.array([lookup[i] for i in index_max])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-S8DmJQaxS",
        "outputId": "c6232cea-1adf-4272-865e-492889c75e14"
      },
      "source": [
        "# a value of one means we detected the action!\r\n",
        "predicted_labels[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}