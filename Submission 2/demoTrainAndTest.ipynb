{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demoTrainAndTest.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srPHiZhPjbCF"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9fmd4KnymJr"
      },
      "source": [
        "# Provides similar functionality to ImageDataGenerators for videos\r\n",
        "!pip install keras-video-generators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2nHw4R7yp3C"
      },
      "source": [
        "# Please email me at nini16@tamu.edu if you do not ave access to the google drive.\r\n",
        "# Permissions should have been granted but if not please email me!\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')\r\n",
        "# drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAekXi4cBlGL"
      },
      "source": [
        "# !rm -rf \"/content/drive/MyDrive/CSCE636/Weights\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA_Vh5HTzPjH"
      },
      "source": [
        "# training data.\r\n",
        "# Please ensure the file is present before running.\r\n",
        "!unzip -q \"/content/drive/MyDrive/CSCE636/new_train_2_classes.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrBsbdoWyXgq"
      },
      "source": [
        "import keras\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from keras.layers import Conv2D, BatchNormalization, \\\r\n",
        "    MaxPool2D, GlobalMaxPool2D, Dense, Dropout\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras_video import VideoFrameGenerator\r\n",
        "\r\n",
        "from keras.layers import TimeDistributed, GRU, Dense, Dropout\r\n",
        "\r\n",
        "from keras.models import load_model\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Xx0DXOzJ30"
      },
      "source": [
        "# All frames should be resized\r\n",
        "# Please select a batch-size that divides the number of samples!\r\n",
        "# THE DATASET WILL PROBABLY BE INCREASED FOR THE NEXT SUBMISSION SO\r\n",
        "# BE SURE TO ADJUST THE BATCH SIZE!!\r\n",
        "\r\n",
        "img_shape = (224, 224)\r\n",
        "BS = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kS-o0BZzJ7v"
      },
      "source": [
        "# Apply image augmentation to each frame\r\n",
        "# Please confirm that this directory is present before running\r\n",
        "\r\n",
        "vid_gen = VideoFrameGenerator(\r\n",
        "    glob_pattern=r\"/content/new_train_2_classes/{classname}/*\",\r\n",
        "    nb_frames=5,\r\n",
        "    split_val=.15, \r\n",
        "    shuffle=True,\r\n",
        "    batch_size=BS,\r\n",
        "    target_shape=img_shape,\r\n",
        "    nb_channel=3,\r\n",
        "    transformation=ImageDataGenerator(rescale=1./255,\r\n",
        "                                      rotation_range=30,\r\n",
        "                                      # width_shift_range=0.1,\r\n",
        "                                      # height_shift_range=0.1,\r\n",
        "                                      # shear_range=0.1,\r\n",
        "                                      zoom_range=0.1,\r\n",
        "                                      horizontal_flip=True,\r\n",
        "                                      fill_mode=\"nearest\"),\r\n",
        "    use_frame_cache=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqbQiJKp784D"
      },
      "source": [
        "validation_gen = vid_gen.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyHmq9w85Tfn"
      },
      "source": [
        "# Can use this for visualization\r\n",
        "# from keras_video import utils\r\n",
        "# utils.show_sample(vid_gen, random=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxiE9U_YzJ_2"
      },
      "source": [
        "# model structure for Feature Extractor\r\n",
        "def build_convnet_2(shape=(224, 224, 3)):\r\n",
        "    momentum = .9\r\n",
        "    model = keras.Sequential()\r\n",
        "    model.add(Conv2D(64, (3,3), input_shape=shape,\r\n",
        "        padding='same', activation='relu', name='conv1'))\r\n",
        "    model.add(Conv2D(64, (3,3), padding='same', activation='relu', name='conv2'))\r\n",
        "    model.add(BatchNormalization(momentum=momentum))\r\n",
        "    \r\n",
        "    model.add(MaxPool2D())\r\n",
        "    \r\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu', name='conv3'))\r\n",
        "    model.add(Conv2D(128, (3,3), padding='same', activation='relu', name='conv4'))\r\n",
        "    model.add(BatchNormalization(momentum=momentum))\r\n",
        "    \r\n",
        "    model.add(MaxPool2D())\r\n",
        "    \r\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu', name='conv5'))\r\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu', name='conv6'))\r\n",
        "    model.add(Conv2D(256, (3,3), padding='same', activation='relu', name='conv7'))\r\n",
        "    model.add(BatchNormalization(momentum=momentum))\r\n",
        "    \r\n",
        "    model.add(MaxPool2D())\r\n",
        "    \r\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu', name='conv8'))\r\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu', name='conv9'))\r\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu', name='conv10'))\r\n",
        "    model.add(BatchNormalization(momentum=momentum))\r\n",
        "\r\n",
        "    model.add(MaxPool2D())\r\n",
        "\r\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu', name='conv11'))\r\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu', name='conv12'))\r\n",
        "    model.add(Conv2D(512, (3,3), padding='same', activation='relu', name='conv13'))\r\n",
        "    model.add(BatchNormalization(momentum=momentum))\r\n",
        "    \r\n",
        "    # flatten...\r\n",
        "    model.add(GlobalMaxPool2D())\r\n",
        "\r\n",
        "    model.add(Dense(512, activation='relu', name='fc1', kernel_regularizer=l2(0.01)))\r\n",
        "    model.add(Dropout(.5))\r\n",
        "    model.add(Dense(256, activation='relu', name='fc2', kernel_regularizer=l2(0.01)))\r\n",
        "    model.add(Dropout(.5))\r\n",
        "    model.add(Dense(8, activation='softmax', name='fc3'))\r\n",
        "\r\n",
        "    model.load_weights(\"/content/drive/MyDrive/CSCE636/Feature_extract_weights_194-1.12.hdf5\")\r\n",
        "    for layer in model.layers:\r\n",
        "        layer.trainable = False\r\n",
        "\r\n",
        "    # Removes fully-connected layers\r\n",
        "    for i in range(4):\r\n",
        "      model.pop()\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RlyaxyBzMf6"
      },
      "source": [
        "def action_model(shape=(5,) + img_shape + (3,), nbout=3):\r\n",
        "    # Create our feature extractor convnet with img_shape input shape\r\n",
        "    convnet = build_convnet_2()\r\n",
        "    \r\n",
        "    # then create our final model\r\n",
        "    model = keras.Sequential()\r\n",
        "    # add the convnet with img_shape shape\r\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\r\n",
        "    # add GRU\r\n",
        "    model.add(GRU(64))\r\n",
        "    # and finally, we make a decision network\r\n",
        "    model.add(Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(l2=0.01)))\r\n",
        "    model.add(Dropout(.2))\r\n",
        "    model.add(Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "    model.summary()\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcVhpRcs3iLk"
      },
      "source": [
        "# instantiate and compile model\r\n",
        "model = action_model()\r\n",
        "optimizer = keras.optimizers.Adam(0.0001)\r\n",
        "model.compile(\r\n",
        "    optimizer,\r\n",
        "    'categorical_crossentropy',\r\n",
        "    metrics=['acc']\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjuNkqG47uXR"
      },
      "source": [
        "# Adjust epochs and other parameters as needed\r\n",
        "# Callbacks have been commented out to avoid overwriting existin data.\r\n",
        "# Whoever is running this can uncomment them as needed\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    # keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=7, min_lr=0.000001),\r\n",
        "    # keras.callbacks.EarlyStopping(\r\n",
        "    #     monitor='val_acc',\r\n",
        "    #     patience=20,\r\n",
        "    #     ),\r\n",
        "    # keras.callbacks.ModelCheckpoint(\r\n",
        "    #     '/content/drive/MyDrive/CSCE636/Weights/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\r\n",
        "    #     monitor='val_acc',\r\n",
        "    #     save_best_only=True,\r\n",
        "    #     verbose=1),\r\n",
        "]\r\n",
        "\r\n",
        "history = model.fit_generator(\r\n",
        "    vid_gen,\r\n",
        "    steps_per_epoch=math.ceil(526/BS),\r\n",
        "    validation_data=validation_gen,\r\n",
        "    verbose=1,\r\n",
        "    epochs=1, # last used 80,\r\n",
        "    shuffle=True,\r\n",
        "    callbacks=callbacks\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_sDIimUedl1"
      },
      "source": [
        "# uncomment only if you need to\r\n",
        "# model.save('/content/drive/MyDrive/CSCE636/main_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYkLneS3eXQ4"
      },
      "source": [
        "# uncomment only if you need to\r\n",
        "# np.save('/content/drive/MyDrive/CSCE636/train_history_main_model.npy',history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gG8n-RzpDo5"
      },
      "source": [
        "\r\n",
        "\r\n",
        "Testing model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Xs4zTDpfL5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lhbKL4Zpt_m"
      },
      "source": [
        "# just in case\r\n",
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBEekqpg6KWA"
      },
      "source": [
        "def ExtractFrames(file_path, pos=[0.1,0.3,0.5,0.7,0.9]):\r\n",
        "    # Extracts frames from file_path at the positions (relative between 0 and 1) in pos\r\n",
        "    \r\n",
        "    import os\r\n",
        "    \r\n",
        "    if not len(pos):\r\n",
        "        print(\"[ExtractFrames]: Invalid positions\")\r\n",
        "        return None\r\n",
        "    \r\n",
        "    if not os.path.isfile(file_path) :\r\n",
        "        print(\"[ExtractFrames]: Invalid file path\")\r\n",
        "        return None\r\n",
        "    \r\n",
        "    import cv2\r\n",
        "    \r\n",
        "    # container for frames\r\n",
        "    arr = np.empty((len(pos),224,224,3))\r\n",
        "    \r\n",
        "    cap = cv2.VideoCapture(file_path)\r\n",
        "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\r\n",
        "    \r\n",
        "    for k,i in enumerate(pos):\r\n",
        "        # get frame number\r\n",
        "        position = int(i * total_frames)\r\n",
        "        \r\n",
        "        # set frame pointer at i and extract frame\r\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\r\n",
        "        ret, frame = cap.read()\r\n",
        "        \r\n",
        "        # preprocessing\r\n",
        "        frame = cv2.resize(frame, (224,224))\r\n",
        "        frame = frame * 1/255.\r\n",
        "        frame = np.float32(frame)\r\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\r\n",
        "        \r\n",
        "        # insert in container\r\n",
        "        arr[k] = frame\r\n",
        "        \r\n",
        "    # cleanup\r\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\r\n",
        "    cap.release()\r\n",
        "    \r\n",
        "    return arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTXF1H9u6MI2"
      },
      "source": [
        "def test_flow_from_directory(dir_path):\r\n",
        "    import numpy as np\r\n",
        "    import os\r\n",
        "    from tqdm import tqdm\r\n",
        "    \r\n",
        "    # 2 classes: \"brushing_teeth\", \"miscellaneous\"\r\n",
        "    posDIR = os.path.join(dir_path, \"brushing_teeth\")\r\n",
        "    negDIR = os.path.join(dir_path, \"miscellaneous\")\r\n",
        "    \r\n",
        "    pos_samples = os.listdir(posDIR)\r\n",
        "    neg_samples = os.listdir(negDIR)\r\n",
        "    \r\n",
        "    # Get all the videos in both classes\r\n",
        "    pos_samples = [os.path.join(posDIR, fname) for fname in pos_samples]\r\n",
        "    neg_samples = [os.path.join(negDIR, fname) for fname in neg_samples]\r\n",
        "    \r\n",
        "    sample_size = len(pos_samples) + len(neg_samples)\r\n",
        "    \r\n",
        "    # Array for data, labels and files \r\n",
        "    test_data   = np.empty( (sample_size, 5, 224, 224, 3) )\r\n",
        "    test_label  = np.empty( (sample_size, 1) )\r\n",
        "    test_files  = pos_samples+neg_samples\r\n",
        "    \r\n",
        "    # Extract frames from all videos using default positions\r\n",
        "    index = 0\r\n",
        "    print(\"Now extracting brushing_teeth videos\")\r\n",
        "    for vid in tqdm(pos_samples):\r\n",
        "        test_data[index] = ExtractFrames(str(vid))\r\n",
        "        test_label[index] = 1.\r\n",
        "        index += 1\r\n",
        "    \r\n",
        "    print(\"Now extracting miscellaneous videos\")\r\n",
        "    for vid in tqdm(neg_samples):\r\n",
        "        test_data[index] = ExtractFrames(vid)\r\n",
        "        test_label[index] = 0.\r\n",
        "        index += 1\r\n",
        "    \r\n",
        "    return test_data, test_label, test_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxIOSkCPtoGI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGKOG0zmtup9"
      },
      "source": [
        "!unzip -q \"/content/drive/MyDrive/CSCE636/YoutubeTest_v2.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt3LuCWitxNU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x8kiax4t3-Z"
      },
      "source": [
        "model = load_model(\"/content/drive/MyDrive/CSCE636/main_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSyDrUcnt5jI"
      },
      "source": [
        "# Loads data, label and filenames\r\n",
        "test_data, test_label, test_files = test_flow_from_directory(\"/content/YoutubeTest_v2\")\r\n",
        "test_label = np.reshape(test_label, test_label.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yXHQGmUuCrB"
      },
      "source": [
        "BS = 50\r\n",
        "num_steps = math.ceil(test_data.shape[0]/BS)\r\n",
        "num_steps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbuOhQgAvEKK"
      },
      "source": [
        "pred = model.predict(test_data,verbose=1,batch_size=50, steps=num_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9dMEQhND96x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZtnTJKJvGb1"
      },
      "source": [
        "index_max = np.argmax(pred, axis=1)\r\n",
        "# \"brushing_teeth\" - 1, \"not brushing_teeth\" - 0\r\n",
        "# if argmax is index 0, then it predicted brushing teeth, hence\r\n",
        "# assign a 1 or else assign a 0\r\n",
        "lookup = {1:0, 0:1}\r\n",
        "predicted_labels = np.array([lookup[i] for i in index_max])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfADBeSevSPn"
      },
      "source": [
        "accuracy_score(test_label, predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOJ8nf_pvwal"
      },
      "source": [
        "confusion_matrix(test_label, predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUausVig7qn4"
      },
      "source": [
        "print(\"False Negative Rate: {}\".format(75/(319+75)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mJSN69S8VN7"
      },
      "source": [
        "print(\"False Positive Rate: {}\".format(145/(214+145)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfTi5MbP9wgx"
      },
      "source": [
        "# import csv\r\n",
        "# fields = ['file', 'Label']\r\n",
        "# expData = []\r\n",
        "# for i in range(394):\r\n",
        "#     expData.append([test_files[i], predicted_labels[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8vfiF4y_pJL"
      },
      "source": [
        "# with open('/content/filecheck.csv', 'w') as f: \r\n",
        "      \r\n",
        "#     # using csv.writer method from CSV package \r\n",
        "#     write = csv.writer(f) \r\n",
        "      \r\n",
        "#     write.writerow(fields) \r\n",
        "#     write.writerows(expData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxfdHiZpD8St"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}