{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "demoTrainAndTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srPHiZhPjbCF"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9fmd4KnymJr",
        "outputId": "54f24a03-4562-4a5c-a395-9a6ae1cc589c"
      },
      "source": [
        "# Provides similar functionality to ImageDataGenerators for videos\n",
        "!pip install keras-video-generators"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-video-generators\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/98/ff550be6084b0537f1340783a6850a2f2b62b87273472a56c17ed84bcdb3/keras-video-generators-1.0.14.tar.gz\n",
            "Requirement already satisfied: keras>=2 in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from keras-video-generators) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2->keras-video-generators) (2.10.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->keras-video-generators) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2->keras-video-generators) (1.15.0)\n",
            "Building wheels for collected packages: keras-video-generators\n",
            "  Building wheel for keras-video-generators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-video-generators: filename=keras_video_generators-1.0.14-cp37-none-any.whl size=12884 sha256=2a17d92927569f54f2cf26216b3527521e673071ab983aa03e7821afb3eeff10\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/b7/76/8674d46fc4777c09e5aa7b065d4e356d90f12ec409a6144bbb\n",
            "Successfully built keras-video-generators\n",
            "Installing collected packages: keras-video-generators\n",
            "Successfully installed keras-video-generators-1.0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2nHw4R7yp3C",
        "outputId": "0f9ecf3d-74fc-455d-9e7e-d8c49e8ebe2c"
      },
      "source": [
        "# Please email me at nini16@tamu.edu if you do not ave access to the google drive.\n",
        "# Permissions should have been granted but if not please email me!\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# drive.flush_and_unmount()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA_Vh5HTzPjH"
      },
      "source": [
        "# training data.\n",
        "# Please ensure the file is present before running.\n",
        "!unzip -q \"/content/drive/MyDrive/CSCE636/v8/dataset_v8.zip\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrBsbdoWyXgq"
      },
      "source": [
        "import keras\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, BatchNormalization, \\\n",
        "    MaxPool2D, GlobalMaxPool2D, Dense, Dropout, Bidirectional\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras_video import VideoFrameGenerator\n",
        "\n",
        "from keras.layers import TimeDistributed, GRU, Dense, Dropout, LSTM\n",
        "\n",
        "from keras.models import load_model, Model\n",
        "\n",
        "from keras.applications import ResNet50V2, DenseNet121\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Xx0DXOzJ30"
      },
      "source": [
        "# All frames should be resized\n",
        "# Please select a batch-size that divides the number of samples!\n",
        "# THE DATASET WILL PROBABLY BE INCREASED FOR THE NEXT SUBMISSION SO\n",
        "# BE SURE TO ADJUST THE BATCH SIZE!!\n",
        "\n",
        "img_shape = (224, 224)\n",
        "BS = 22"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kS-o0BZzJ7v",
        "outputId": "f86258d2-8926-4fa8-d183-4a94b5f87893"
      },
      "source": [
        "# Apply image augmentation to each frame\n",
        "# Please confirm that this directory is present before running\n",
        "\n",
        "vid_gen = VideoFrameGenerator(\n",
        "    glob_pattern=r\"/content/dataset_v8/{classname}/*\",\n",
        "    nb_frames=20, \n",
        "    shuffle=True,\n",
        "    split_val=0.1155,\n",
        "    batch_size=BS,\n",
        "    target_shape=img_shape,\n",
        "    nb_channel=3,\n",
        "    transformation=ImageDataGenerator(rescale=1./255,\n",
        "                                      samplewise_center=True,\n",
        "                                      # rotation_range=30,\n",
        "                                      # width_shift_range=0.1,\n",
        "                                      # height_shift_range=0.1,\n",
        "                                      # shear_range=0.1,\n",
        "                                      # zoom_range=0.1,\n",
        "                                      # horizontal_flip=True,\n",
        "                                      fill_mode=\"nearest\"),\n",
        "    use_frame_cache=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class blowing_nose, validation count: 44, train count: 344\n",
            "class z_miscellaneous, validation count: 44, train count: 338\n",
            "Total data: 2 classes for 682 files for train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqbQiJKp784D",
        "outputId": "75dcc915-5193-4db3-ccff-01ba6b7f8afb"
      },
      "source": [
        "validation_gen = vid_gen.get_validation_generator()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data: 2 classes for 88 files for validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxiE9U_YzJ_2"
      },
      "source": [
        "# model structure for Feature Extractor\n",
        "def build_convnet_3(shape=(224, 224, 3)):\n",
        "    resnet = DenseNet121(include_top=False, weights='imagenet', input_shape=shape)\n",
        "\n",
        "    train = False\n",
        "    for layer in resnet.layers:\n",
        "        layer.trainable = train\n",
        "        if layer.name == \"conv5_block3_2_relu\":\n",
        "            train = True\n",
        "    \n",
        "    globMaxpool = GlobalMaxPool2D()(resnet.output)\n",
        "    model = Model(inputs=resnet.input, outputs=globMaxpool)\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RlyaxyBzMf6"
      },
      "source": [
        "def action_model(shape=(20,) + img_shape + (3,)):\n",
        "    # Create our feature extractor convnet with img_shape input shape\n",
        "    convnet = build_convnet_3()\n",
        "    \n",
        "    # then create our final model\n",
        "    model = keras.Sequential()\n",
        "    # add the convnet with img_shape shape\n",
        "    model.add(TimeDistributed(convnet, input_shape=shape))\n",
        "    # add GRU\n",
        "    model.add(LSTM(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(l2=0.01)))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcVhpRcs3iLk",
        "outputId": "7edde067-d7e3-4494-e97c-ecaff72e1c14"
      },
      "source": [
        "# instantiate and compile model\n",
        "model = action_model()\n",
        "optimizer = keras.optimizers.Adam(0.0005) #0.0005\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 20, 1024)          7037504   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                278784    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              66560     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 7,384,898\n",
            "Trainable params: 347,394\n",
            "Non-trainable params: 7,037,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "scrolled": true,
        "id": "DnPD2K0kQvSD",
        "outputId": "e3a8a33f-2bdc-40e6-ebfe-0e7c3be39452"
      },
      "source": [
        "# Adjust epochs and other parameters as needed\n",
        "# Callbacks have been commented out to avoid overwriting existin data.\n",
        "# Whoever is running this can uncomment them as needed\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, min_lr=0.0001),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_acc',\n",
        "        patience=5,\n",
        "        ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        r'/content/Weights/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "        monitor='val_acc',\n",
        "        save_best_only=True,\n",
        "        verbose=1),\n",
        "]\n",
        "\n",
        "history = model.fit_generator(\n",
        "    vid_gen,\n",
        "    steps_per_epoch=math.ceil(vid_gen.files_count/BS),\n",
        "    validation_data=validation_gen,\n",
        "    verbose=1,\n",
        "    epochs=30, # last used 80,\n",
        "    shuffle=True,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\cotua\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "86/86 [==============================] - 321s 4s/step - loss: 1.5203 - acc: 0.6640 - val_loss: 0.7254 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.90625, saving model to C:\\Users\\cotua\\Desktop\\python scripts\\Weights\\weights.01-0.73.hdf5\n",
            "Epoch 2/30\n",
            "86/86 [==============================] - 82s 956ms/step - loss: 0.6511 - acc: 0.8896 - val_loss: 0.4675 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.90625 to 0.91250, saving model to C:\\Users\\cotua\\Desktop\\python scripts\\Weights\\weights.02-0.47.hdf5\n",
            "Epoch 3/30\n",
            "86/86 [==============================] - 82s 954ms/step - loss: 0.4352 - acc: 0.9194 - val_loss: 0.3599 - val_acc: 0.9250\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.91250 to 0.92500, saving model to C:\\Users\\cotua\\Desktop\\python scripts\\Weights\\weights.03-0.36.hdf5\n",
            "Epoch 4/30\n",
            "86/86 [==============================] - 82s 958ms/step - loss: 0.3185 - acc: 0.9412 - val_loss: 0.3275 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92500\n",
            "Epoch 5/30\n",
            "86/86 [==============================] - 82s 954ms/step - loss: 0.2718 - acc: 0.9379 - val_loss: 0.2341 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.92500 to 0.95000, saving model to C:\\Users\\cotua\\Desktop\\python scripts\\Weights\\weights.05-0.23.hdf5\n",
            "Epoch 6/30\n",
            "86/86 [==============================] - 82s 956ms/step - loss: 0.1999 - acc: 0.9567 - val_loss: 0.1975 - val_acc: 0.9563\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.95000 to 0.95625, saving model to C:\\Users\\cotua\\Desktop\\python scripts\\Weights\\weights.06-0.20.hdf5\n",
            "Epoch 7/30\n",
            "86/86 [==============================] - 82s 954ms/step - loss: 0.1510 - acc: 0.9745 - val_loss: 0.2120 - val_acc: 0.9312\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.95625\n",
            "Epoch 8/30\n",
            "86/86 [==============================] - 82s 954ms/step - loss: 0.1524 - acc: 0.9714 - val_loss: 0.1638 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.95625\n",
            "Epoch 9/30\n",
            "86/86 [==============================] - 82s 953ms/step - loss: 0.1160 - acc: 0.9794 - val_loss: 0.1874 - val_acc: 0.9375\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.95625\n",
            "Epoch 10/30\n",
            "86/86 [==============================] - 82s 954ms/step - loss: 0.0899 - acc: 0.9904 - val_loss: 0.1569 - val_acc: 0.9375\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.95625\n",
            "Epoch 11/30\n",
            "86/86 [==============================] - 82s 954ms/step - loss: 0.0641 - acc: 0.9965 - val_loss: 0.1822 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.95625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_sDIimUedl1"
      },
      "source": [
        "# uncomment only if you need to\n",
        "model.save(r'C:\\Users\\cotua\\Desktop\\python scripts\\BLSTM_model_V8_lr_0.0005.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYkLneS3eXQ4"
      },
      "source": [
        "# uncomment only if you need to\n",
        "np.save(r'C:\\Users\\cotua\\Desktop\\python scripts\\train_history_BLSTM_model_V8_lr_0.0005.npy',history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gG8n-RzpDo5"
      },
      "source": [
        "**Testing model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d32FKoX90v6"
      },
      "source": [
        "model=load_model(r'/content/drive/MyDrive/CSCE636/v8/BLSTM_model_V8_lr_0.0005.h5')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BfUQoELCCWw"
      },
      "source": [
        "!unzip -q \"/content/drive/MyDrive/CSCE636/v8/youtube-neg-test.zip\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfXkwlvNCaXO"
      },
      "source": [
        "!unzip -q \"/content/drive/MyDrive/CSCE636/v8/youtube_positive.zip\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Xs4zTDpfL5"
      },
      "source": [
        "Positive Youtube Videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKuihExs-tQp",
        "outputId": "164d1399-ad48-4006-97b1-4f336d723bcd"
      },
      "source": [
        "test_gen = VideoFrameGenerator(\n",
        "    glob_pattern=r\"/content/youtube_positive/{classname}/*\",\n",
        "    nb_frames=20, \n",
        "    shuffle=False,\n",
        "    batch_size=10,\n",
        "    target_shape=img_shape,\n",
        "    nb_channel=3,\n",
        "    transformation=ImageDataGenerator(rescale=1./255,\n",
        "                                      samplewise_center=True,\n",
        "                                      # rotation_range=30,\n",
        "                                      # width_shift_range=0.1,\n",
        "                                      # height_shift_range=0.1,\n",
        "                                      # shear_range=0.1,\n",
        "                                      # zoom_range=0.1,\n",
        "                                      # horizontal_flip=True,\n",
        "                                      fill_mode=\"nearest\"),\n",
        "    use_frame_cache=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data: 2 classes for 290 files for train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGofq3RTSgA7",
        "outputId": "558ef26d-845d-442e-d530-2d0f7e044d51"
      },
      "source": [
        "len(test_gen)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ApYRWhT90v7"
      },
      "source": [
        "# Run for only 5 steps since google colab cant handle entire test set\n",
        "model.evaluate_generator(test_gen, steps=len(test_gen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LF496IDBog5"
      },
      "source": [
        "Negative Youtube Videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFKdOtiwB5Km",
        "outputId": "7437c08c-a14e-4c9a-8715-70d855ec4c4c"
      },
      "source": [
        "test_gen = VideoFrameGenerator(\n",
        "    glob_pattern=r\"/content/youtube-neg-test/{classname}/*\",\n",
        "    nb_frames=20, \n",
        "    shuffle=True,\n",
        "    batch_size=10,\n",
        "    target_shape=img_shape,\n",
        "    nb_channel=3,\n",
        "    transformation=ImageDataGenerator(rescale=1./255,\n",
        "                                      samplewise_center=True,\n",
        "                                      # rotation_range=30,\n",
        "                                      # width_shift_range=0.1,\n",
        "                                      # height_shift_range=0.1,\n",
        "                                      # shear_range=0.1,\n",
        "                                      # zoom_range=0.1,\n",
        "                                      # horizontal_flip=True,\n",
        "                                      fill_mode=\"nearest\"),\n",
        "    use_frame_cache=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total data: 2 classes for 310 files for train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JcW4UI996c-",
        "outputId": "88f9fe2d-6364-4738-ebf4-ebb60685bb0a"
      },
      "source": [
        "len(test_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_OlorkB7Lw"
      },
      "source": [
        "model.evaluate_generator(test_gen, steps=len(test_gen))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}